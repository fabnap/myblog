<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="f napolitano" />
        <title>Fabnap Blog</title>
        <link rel="icon" type="image/x-icon" href="assets/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v5.15.4/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />

        <!-- here for the highlight js -->
        <!--  -->
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/default.min.css">
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/highlight.min.js"></script>
        <!-- and it's easy to individually load additional languages -->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/languages/python.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>
        <!--  -->
        <!--  -->


    </head>
    <body>
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-light" id="mainNav">
            <div class="container px-4 px-lg-5">
                <a class="navbar-brand" href="index.html">FabNap Blog</a>
                <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
                    Menu
                    <i class="fas fa-bars"></i>
                </button>
                <div class="collapse navbar-collapse" id="navbarResponsive">
                    <ul class="navbar-nav ms-auto py-4 py-lg-0">
                        <li class="nav-item"><a class="nav-link px-lg-3 py-3 py-lg-4" href="index.html">Home</a></li>
                        <li class="nav-item"><a class="nav-link px-lg-3 py-3 py-lg-4" href="about.html">About</a></li>
                        <li class="nav-item"><a class="nav-link px-lg-3 py-3 py-lg-4" href="contact.html">Contact</a></li>
                    </ul>
                </div>
            </div>
        </nav>
        <!-- Page Header-->
        <header class="masthead" style="background-image: url('https://upload.wikimedia.org/wikipedia/commons/0/08/Polycrystalline-germanium.jpg')">
            <div class="container position-relative px-4 px-lg-5">
                <div class="row gx-4 gx-lg-5 justify-content-center">
                    <div class="col-md-10 col-lg-8 col-xl-7">
                        <div class="post-heading">
                            <h1>1D Convolutional Network for pulse shape discrimination</h1>
                            <h2 class="subheading">Discriminate signals from detectors with Keras</h2>
                            <span class="meta">
                            Posted by
                            <a href="#!">FabNap</a>
                            on March 10, 2022
                            </span>
                        </div>
                    </div>
                </div>
            </div>
        </header>
        <center>
        <small><span class="caption text-muted">CC BY 3.0, via Wikimedia Commons</span></small>
        </center>
        <!-- Post Content-->
        <article class="mb-4">
            <div class="container px-4 px-lg-5">
                <div class="row gx-4 gx-lg-5 justify-content-center">
                    <div class="col-md-10 col-lg-8 col-xl-10">
                        <p align="justify">In this post I'll show how to setup a Keras work flow for discrimination of certain kind of shapes. First let's see (very briefly) what we are talking about. </p>
                        <center>
                        <h2 class="section-heading">The Problem</h2>
                        <!-- <a href="#!"><img class="img-fluid" ="assets/img/post-sample-image.jpg" alt="..." 
                            /></a> -->
                            <a title="TQB1, CC BY-SA 3.0 &lt;https://creativecommons.org/licenses/by-sa/3.0&gt;, via Wikimedia Commons" href="https://commons.wikimedia.org/wiki/File:Laboratori_Nazionali_del_Gran_Sasso,_INFN_(TQB1)_2014-02.jpg"><img alt="Laboratori Nazionali del Gran Sasso, INFN (TQB1) 2014-02" src="https://upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Laboratori_Nazionali_del_Gran_Sasso%2C_INFN_%28TQB1%29_2014-02.jpg/512px-Laboratori_Nazionali_del_Gran_Sasso%2C_INFN_%28TQB1%29_2014-02.jpg"></a>
                            </center>
                        <span class="caption text-muted"><a href="https://commons.wikimedia.org/wiki/File:Laboratori_Nazionali_del_Gran_Sasso,_INFN_(TQB1)_2014-02.jpg">INFN's underground lab, Italy, TQB1</a>, <a href="https://creativecommons.org/licenses/by-sa/3.0"> CC BY-SA 3.0</a>, via Wikimedia Commons</span>
                        <p align="justify">
                        Let's say we want to investigate Nature at a microscopic scale. Quantum Mechanics is the theory we want to use when dealing with atoms, electrons, nuclei. It is a very well established theory, about a hundred years old, and superbly successful. 
                        Quantum Mechanics states that microscopic entities are not really localized, rather they are described via a so called <i>wave-function</i>. The wave-function can do all sort of weird things, like <a href="https://en.wikipedia.org/wiki/Quantum_tunnelling">tunnel through barriers</a>, or be in a <i>superposition</i> of different states. It is the case of the famous <a href="https://en.wikipedia.org/wiki/Schr%C3%B6dinger%27s_cat">Schr√∂dinger's cat paradox</a>. Whenever an observation is made, the wave-function collapses in one of the states, for example dead or alive cat.</p>
                        <p align="justify">However this mechanism is not really satisfying from a theoretical point of view: it does not come from some fundamental assumption, moreover it is not clear the boundary between microscopic and macroscopic world. At what point a group of molecules stop behaving in this way for example? Different theories have been put forward. Long (very long) story short, these theories predict emission of spontaneous radiation, which scientists are looking for in the underground labs as in the picture above.</p>
                        <p align="justify">
                        For this we are using a particular radiation detector, which is based on germanium crystal with very high purity. Germanium is a semiconductor, just like silicon, and in certain conditions and arrangements, it produces electric pulses when its volume is hit by an energetic photon.
                        </p> 
                        <p>Now, the problem here is that we want to classify the pulses in:</p>
                        <ul>
                            <li>Good Pulses: these are events generated by a single photon</li>
                            <li>Multi-Event Pulses: it can happen multiple photons from different processes are generate, they should be discarded</li>
                            <li>Noise Pulses: these come purely from electronic noise and show be discarded as well.</li>
                        </ul>
                        <p>Let's generate some synthetic pulses to show how they look like:</p>

                        <pre class="python">
                        <code >
# generating the data
import math
from scipy import special
from scipy.stats import norm

import colorednoise as cn

MovAvg= 40
xplt = np.arange(0,924+MovAvg-1,1)
x = np.arange(0,924,1)

tail = norm.pdf(xplt,200,50)

y_np = []
label = []
# good shapes
for i in range(0,1000):
  center = np.random.normal(300,10)
  y = (special.erf((xplt-center)/70)+1)/2
  decrease = []
  scale=abs(np.random.normal(5,10))
  scalenoise=abs(np.random.normal(  1,2 ) )

  for k in range(0,len(x)):
    if k < center:
      decrease.append( tail[k]*scale  )
    else:
      decrease.append(-0.0001*k + (0.0001*center))
  decrease = np.array(decrease)

  noise = abs(np.random.normal(0,0.05))
  y = y + 0.01*scalenoise*cn.powerlaw_psd_gaussian(1, 924+MovAvg-1)

  ycnv=np.convolve(y, np.ones(MovAvg)/MovAvg, mode='valid')
  ycnv = ycnv + decrease

  y_np.append( ycnv  )
  label.append( np.array([1,0,0]) ) # good shapes

# bad shapes
for i in range(0,1000):

  noise = abs(np.random.normal(0,0.05))
  y = cn.powerlaw_psd_gaussian(1, 924+MovAvg-1)
  ycnv=np.convolve(y, np.ones(MovAvg)/MovAvg, mode='valid')
  massimo = max(ycnv)
  minimo = min(ycnv)
  yappend = [(i-minimo )/(massimo - minimo ) for i in ycnv]

  y_np.append( yappend  )
  label.append( np.array([0,0,1]) ) # bad shapes



# double shapes
for i in range(0,1000):
  center = np.random.normal(300,10)
  shift = 100
  y = (special.erf((xplt-center)/35)+1)/4 + (special.erf((xplt-(center+shift))/35)+1)/4
  decrease = []
  scale=abs(np.random.normal(5,10))
  scalenoise=abs(np.random.normal(  1,2 ) )


  for k in range(0,len(x)):
    if k < center:
      decrease.append( tail[k]*scale  )
    else:
      decrease.append(-0.0001*k + (0.0001*center))
  noise = abs(np.random.normal(0,0.05))

  y = y + 0.01*scalenoise*cn.powerlaw_psd_gaussian(1, 924+MovAvg-1)

  ycnv=np.convolve(y, np.ones(MovAvg)/MovAvg, mode='valid')
  ycnv = ycnv + decrease


  y_np.append( ycnv  )
  label.append( np.array([0,1,0]) ) # double shapes


label = np.array(label)
y_np = np.array(y_np)
                        </code>
                        </pre>

                        <p align="justify"> Quick explanation on this ones. First of all, the pulses look like sigmoid or error functions, so we just start using <code>(special.erf(x)+1)/2</code> so that it is always positive in its domain, with its centre and width adjusted to match the data.
                        For the Multi-Event ones, we just sum two slightly shifted.
                        The noise events and the noise inside the other two is a flicker noise which can be conveniently generated from the nice "colorednoise" package. Here below some examples, which are normalized to one for convenience. The scale of the noise is also random, to make sure the model is robust to a certain degree against that.
                        </p>    


                        <div class="row">
                            <div class="column">
                                <img src="assets/img/post1/pic1.png"  style="width:30%">
                                This is a good one; the energy of the photon is the relative height.
                            </div>
                            <div class="column">
                                <img src="assets/img/post1/pic3.png"  style="width:30%">
                                This is a Multi-Event pulse, which is a sum of more unknown effect.
                            </div>
                            <div class="column">
                                <img src="assets/img/post1/pic2.png"  style="width:30%">
                                This is just electronic noise, and should be discarded.
                            </div>
                        </div> 

                        <p align="justify">
                        Now, the problem here is that we have so many pulses, that discriminate them one by one would take a very long time. Of course there is always an algorithmic solution, however this has typically to many parameters to fine-tune, plus we want to use this occasion for some good ML.
                        </p> 

                        <h2 class="section-heading" align="center">Solution with Keras</h2>
                        <pre class="python">
                        <code>
from tensorflow import keras
from keras.preprocessing import sequence
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Conv1D, GlobalMaxPooling1D, Embedding, Input
from keras.datasets import imdb
# from keras.utils import plot_model
from keras import optimizers
import matplotlib.pyplot as plt
import numpy as np
# Graphic output
from IPython.display import SVG
from keras.utils.vis_utils import model_to_dot
from sklearn.model_selection import train_test_split

# python3.7
# tested with:
# Name: keras
# Version: 2.6.0
# Name: tensorflow
# Version: 2.6.2
                        </code>
                        </pre>
                        <p align="justify">
                            This are just the basic import for some good ML. 
                            For the training and validation we are going to use the 3k shapes generated above.
                            Let's split in training and validation, and 'label' contains the true classification (we know cause we made them!).
                        </p>
                        <pre class="python">
                        <code>
X_train, X_test, y_train, y_test = train_test_split(y_np, label, test_size=0.33)
X_train=np.array(X_train,None)
                        </code> 
                        </pre>  
                        <p align="justify"> Now we have to specify the architecture of the Convolutional NN. 
                        It will take as input a vector which represents the pulse. We can think about it as a one-dimensional image. Then we apply some convolutional layers, three in this example, and will end up with a classic neural network for the classification.
                        The last layer is made out of three neurons, each one will specify a probability for the different classes. 
                        </p>
                        <pre class="python">
                        <code>
print('Build model...')
model = Sequential()
model.add(Input(shape=(924,1)))
model.add(Conv1D(filters=64,
                 kernel_size=5,
                 padding='valid',
                 activation='relu',
                 strides=1,
                 data_format="channels_last"

                 ))
model.add(Conv1D(filters=64,
                 kernel_size=5,
                 padding='valid',
                 activation='relu',
                 strides=1,
                 data_format="channels_last"
                 ))
model.add(Conv1D(filters=64,
                 kernel_size=5,
                 padding='valid',
                 activation='relu',
                 strides=1,
                 data_format="channels_last"
                 ))
model.add(GlobalMaxPooling1D())
model.add(Dense(200))
model.add(Activation('relu'))
model.add(Dense(100))
model.add(Activation('relu'))
model.add(Dense(3, activation='sigmoid'))

model.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])
model.summary()
                        </code> 
                        </pre>  
                        <p align="justify"> Now it's already time for the training:</p>
                        <pre class='python'>
                        <code>
history = model.fit(X_train, y_train,
batch_size=32,
epochs=14,
validation_data=(X_test, y_test))
                        </code>
                        </pre>
                        <p align="justify">This step should take a while. The number of epochs tells us how many iterations we are going to have. It should not be too large or we risk the model to over-fit. Finally, let's have a look at how was the training, and if our architecture actually learned something</p>
                        <pre class='python'>
                        <code>
history_dict = history.history
history_dict.keys()

val_loss = history.history['val_loss']
loss = history.history['loss']
accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']

epochs = range(1, len(accuracy) + 1)

plt.rcParams['figure.figsize'] = [10, 5]
plt.subplot(1, 2, 1)
plt.plot(epochs, loss, 'bo', label='Training loss', color='red')
plt.plot(epochs,val_loss , 'b', label='Validation loss', color='green')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(epochs, accuracy, 'bo', label='Training acc', color='red')
plt.plot(epochs, val_accuracy, 'b', label='Validation acc', color='green')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.tight_layout()
# plt.show()
plt.savefig("ML/training.png")
model.save("ML/begemodel")
                    </code> 
                    </pre>  
                    <img src="assets/img/post1/pic4.png"  style="width:100%">
                    <p align="adjust"> Here the left plot shows, for each epoch, how "close" the parameters are to the global minimum, or better how much they are moving towards it. If the loss is small, we are close enough. The right plot instead shows the accuracy. This is obtained comparing the prediction against the "truth" which we fed to the system. 
                    We can see that between 3 and 8 epochs, the accuracy was stable around 0.7. This is because the model did learn to discriminate noise vs all the other stuff, but not single and multi-event shapes. However, some more training and the problems is solved, as accuracy reaches around 100%.
                    </p>    
                    <p align="adjust">We can save the model to retrieve it for later without the need of re-training  </p> 
                    <pre class="pyt">
                        <code>
model.save("my_model")
...
model=keras.models.load_model("my_model")

prediction = model.predict(candidates)
                        </code>
                    </pre>
                    <p align="justify"> Where the last line tells the model to make its prediction to a set of candidates (candidates is a np array). Here below some example of our mode applied to real-life data:</p>


                    <div class="row">
                        <div class="column">
                            <img src="assets/img/post1/pic5.png"  style="width:30%">
                            99% good shape. Got this!
                        </div>
                        <div class="column">
                            <img src="assets/img/post1/pic6.png"  style="width:30%">
                            96% multi-event. Correct!
                        </div>
                        <div class="column">
                            <img src="assets/img/post1/pic7.png"  style="width:30%">
                            100% noise, also correct.
                        </div>
                    </div> 


                    <h2 class="section-heading" align="center">Conclusion</h2>
                    <p align="justify">This post shows how to setup a very simple model using convolutional neural nets for classification of pulses from germanium detectors. Works like a charm! Even if usually time-series are better described by recurrent neural networks, in this case the shapes have well defined behaviours and probably the convolutional approach works best.

                    For a more in-depth reading of Deep Learning on germanium detectors, a nice article can be found <a href="https://doi.org/10.1140/epjc/s10052-019-6869-2">here</a>, in this case using variational autoencoders.
                    </p>
                    </div>
                </div>
            </div>
        </article>
        <!-- Footer-->
        <footer class="border-top">
            <div class="container px-4 px-lg-5">
                <div class="row gx-4 gx-lg-5 justify-content-center">
                    <div class="col-md-10 col-lg-8 col-xl-7">
                        <ul class="list-inline text-center">
                            <li class="list-inline-item">
                                <a href="https://www.linkedin.com/in/fabrizio-napolitano-64b4a9168/">
                                    <span class="fa-stack fa-lg">
                                        <i class="fas fa-circle fa-stack-2x"></i>
                                        <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a>
                            </li>
                            <!-- <li class="list-inline-item">
                                <a href="#!">
                                    <span class="fa-stack fa-lg">
                                        <i class="fas fa-circle fa-stack-2x"></i>
                                        <i class="fab fa-facebook-f fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a>
                            </li> -->
                            <li class="list-inline-item">
                                <a href="https://github.com/fabnap">
                                    <span class="fa-stack fa-lg">
                                        <i class="fas fa-circle fa-stack-2x"></i>
                                        <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a>
                            </li>
                        </ul>
                        <div class="small text-center text-muted fst-italic">Copyright &copy; FabNap 2021</div>
                    </div>
                </div>
            </div>
        </footer>
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>
